---
title: "빅데이터 관련 면접 질문 리스트"
date: 2021-11-18T12:24:00+09:00
categories:
  - 메모
tags:
  - 빅데이터
  - 스파크
  - 하둡
header:
  teaser: /assets/images/slipBox.jpg
---

### JPA의 더티체킹이란?

- JPA 엔티티 매니저의 메서드에는 수정에 해당하는 메서드가 없고 더티체킹을 제공한다.
- JPA에서는 트랜잭션 안에서 엔티티의 변경이 일어나면, 변경 내용을 자동으로 데이터베이스에 반영한다. 이를 더티체킹이라고 한다.

### HDFS란?

- 하둡 파일 시스템의 약자이다.
- 네임노드와 데이터 노드로 구성되어 있다.
- 블록 단위로 데이터를 저장하고, 블록 복제를 이용하여 장애를 복구하며, 읽기 중심이라는 특징을 가진다.

### 네임노드란?

- 메타데이터를 관리하여 데이터 노드를 관리한다.
- 네임스페이스와 블록 정보를 저장하는 Fsimage와 파일의 생성 삭제에 대한 트랜잭션 로그가 담긴 Edits로 구성된다.

### HDFS의 이레이져 코딩

- 버전 3부터 도입되었으며, 패리티 블록을 이용하여 HDFS 데이터 저장의 효율성을 증가시키는 것. 이레이저 코드를 사용하여 데이터를 인코딩하고, 데이터가 손실되면 디코딩하여 원본 데이터를 복구하는 기법이다. 최대 k개의 데이터가 손실되어도 n개의 데이터만 살아 있으면 원본 데이터가 복구 가능하다록 인코딩과 디코딩을 한다.

### YARN

- 리소스/노드 매니저로 자원관리, 애플리케이션 마스터로 라이플 사이클 관리하는 아키텍쳐
- 잡트래커 한대로 모든 클러스터의 모든 노드를 관리하면서 맵리듀스, SQL 기반 작업 처리, 인메모리 기반 작업 처리가 어렵기에 도입되었다.

### 맵리듀스란

- 간단한 단위 작업을 반복하여 처리할 때 사용하는 프로그래밍 모델. 단위 작업을 처리하는 맵과, 모아서 집계하는 리듀스 단계로 구성된다.

### 맵리듀스의 셔플

- 맵리듀스의 처리 단계 중 하나로 맵에서 분할되어 키별로 처리된 입력 데이터를 각 리듀서로 이동시키는 단계이다.

### 스파크의 자료구조

스파크의 자료구조는 3가지가 존재한다. RDD, DataFrame, Dataset 순으로 도입되었다.

- RDD는 Resilient Distributed Dataset이다. Linage를 통하여 Fault Tolerant를 보장하며 MapReduce 작업 친화적이다.
- DataFrame부터 Catalyst Optimizer로 최적화를 한다. 스키마를 가지고 있고 정형화되어 있다.
- Dataset은 Type-safe한 기능을 지원한다. Anaylsis Error를 Runtime이 아니라 Compiletime에 잡을 수 있다.

### 하이브

- 데이터 웨어하우징용 솔루선
- HDFS에 저장된 데이터의 구조를 정의하는 방법, HiveQl 쿼리 이용하여 데이터를 조회하는 방법 제공.

### 하이브 메타스토어란?

- 하이브의 메타정보를 보관하고 사용자의 요청에 따라서 관련 정보를 제공하는 곳.
- 메타정보란 파일의 물리적인 위치나 데이터에 대한 논리적인 정보
- 쓰리프트 프로토콜을 이용한다.
- JDBC 드라이버를 이용하여 RDBMS에 저장된다.

### 크로스 사이트 스크립팅(XSS)

- 악성 스크립트를 삽입하여 의도하지 않은 명령을 실행시키거나 세션 등을 탈취하는 취약점.
- 입력 값의 길이 제한, replace 함수 등을 이용한 치환, 입력 값 검사.

### 사이트간 요청 위조(CSRF)

- 권한을 도용하여 특정 웹사이트의 기능을 실행하도록 한다.
- 피싱 사이트에 접속한 희생자가 공격할 사이트에 위조 요청을 보내게 된다.
- CSRF 토큰을 사용한 방어: 사용자의 세션에 임의의 값을 저장하여 모든 요청마다 그 값을 포함하여 전송한다. 요청이 들어올 때마다 백엔드에서 세션에서 저장된 값과 요청으로 전송된 값이 일치하는지 검증한다. 그런데 이는 XSS를 통한 공격법에 약하다.
